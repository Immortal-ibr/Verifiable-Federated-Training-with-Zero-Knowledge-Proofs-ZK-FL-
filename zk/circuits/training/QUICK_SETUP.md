# Component B: Training Integrity Proof - Quick Setup Guide

**Component:** Training Integrity Proof (Component B)  
**Date:** November 11, 2025  
**Status:** âœ… Implementation Complete

---

## Quick Start (5 Minutes)

### Prerequisites

```bash
# Make sure you have:
- Node.js >= 16
- Python >= 3.8
- circom compiler (see Component A setup)
- snarkjs
- circomlib (already installed)
```

### Step 1: Generate Test Data

```bash
# Navigate to training circuit directory
cd zk/circuits/training/

# Run test data generator
python generate_test_data.py \
  --batch-size 8 \
  --model-dim 32 \
  --output test_input.json

# Expected output:
#   ============================================================
#   COMPONENT B TEST - Training Integrity Proof Data Generation
#   ============================================================
#   
#   Configuration:
#     Batch size: 8
#     Model dimension: 32
#     Dataset size: 128
#     Learning rate (Î±): 0.01
#     Clipping threshold (Ï„): 1.0
#   
#   ... (generation steps) ...
#   
#   âœ… Test data saved to: test_input.json
```

### Step 2: Inspect Generated Data

```bash
# View the test input
cat test_input.json

# Should see:
# {
#   "client_id": "1",
#   "root_D": "12345...",    # Dataset commitment
#   "root_G": "67890...",    # Gradient commitment
#   "alpha": "10",           # Learning rate (0.01 * 1000)
#   "tau": "1000",           # Clipping threshold (1.0 * 1000)
#   "weights_old": [...],    # 32 fixed-point values
#   "features": [...],       # 8x32 matrix
#   "labels": [...],         # 8 values
#   "siblings": [...],       # Merkle proofs
#   "pathIndices": [...]     # Merkle paths
# }
```

### Step 3: Verify Data Integrity (Optional)

```python
# Quick Python verification
import json

with open('test_input.json') as f:
    data = json.load(f)

# Check dimensions
assert len(data['weights_old']) == 32, "Wrong model dimension"
assert len(data['features']) == 8, "Wrong batch size"
assert len(data['features'][0]) == 32, "Wrong feature dimension"
assert len(data['labels']) == 8, "Wrong number of labels"
assert len(data['siblings']) == 8, "Wrong number of Merkle proofs"

print("âœ“ All dimensions correct!")

# Check fixed-point encoding
PRECISION = 1000
alpha_value = int(data['alpha']) / PRECISION
tau_value = int(data['tau']) / PRECISION

print(f"âœ“ Learning rate: {alpha_value}")
print(f"âœ“ Clipping threshold: {tau_value}")
```

---

## Full Circuit Compilation & Testing

### Step 1: Compile the Circuit

```bash
# Go to project root
cd "/path/to/Verifiable-Federated-Training-with-Zero-Knowledge-Proofs-ZK-FL-"

# Create build directory
mkdir -p build/training

# Compile circuit
circom zk/circuits/training/sgd_step.circom \
  --r1cs \
  --wasm \
  --sym \
  -o build/training

# Expected output:
#   template instances: 523
#   non-linear constraints: ~245,000
#   linear constraints: 0
#   public inputs: 5
#   private inputs: ~2,100
#   public outputs: 0
#   wires: ~247,000
#   labels: ~250,000
```

### Step 2: Check Circuit Info

```bash
# Install snarkjs if not already installed
npm install -g snarkjs

# View circuit statistics
snarkjs r1cs info build/training/sgd_step.r1cs

# Expected output:
#   [INFO]  snarkJS: Curve: bn-128
#   [INFO]  snarkJS: # of Wires: ~247,000
#   [INFO]  snarkJS: # of Constraints: ~245,000
#   [INFO]  snarkJS: # of Private Inputs: ~2,100
#   [INFO]  snarkJS: # of Public Inputs: 5
#   [INFO]  snarkJS: # of Labels: ~250,000
#   [INFO]  snarkJS: # of Outputs: 0
```

### Step 3: Setup Phase (One-Time)

```bash
# Download powers of tau (need 2^18 for ~245k constraints)
wget https://hermez.s3-eu-west-1.amazonaws.com/powersOfTau28_hez_final_18.ptau

# Generate proving key
snarkjs groth16 setup \
  build/training/sgd_step.r1cs \
  powersOfTau28_hez_final_18.ptau \
  build/training/training_0000.zkey

# Contribute randomness
snarkjs zkey contribute \
  build/training/training_0000.zkey \
  build/training/training_final.zkey \
  --name="Your Name" \
  -v

# Export verification key
snarkjs zkey export verificationkey \
  build/training/training_final.zkey \
  build/training/vkey.json

# Verify the keys were generated
ls -lh build/training/*.zkey build/training/vkey.json
```

### Step 4: Generate Witness

```bash
# Generate witness from test input
node build/training/sgd_step_js/generate_witness.js \
  build/training/sgd_step_js/sgd_step.wasm \
  zk/circuits/training/test_input.json \
  build/training/witness.wtns

# Expected output:
#   [INFO]  snarkJS: Witness generated successfully
```

### Step 5: Generate Proof

```bash
# Generate ZK proof
snarkjs groth16 prove \
  build/training/training_final.zkey \
  build/training/witness.wtns \
  build/training/proof.json \
  build/training/public.json

# Expected output:
#   [INFO]  snarkJS: Reading R1CS
#   [INFO]  snarkJS: Reading zkey
#   [INFO]  snarkJS: Generating proof...
#   [INFO]  snarkJS: Proof generated successfully

# Check proof size
ls -lh build/training/proof.json
# Should be ~192 bytes (Groth16 is very compact!)
```

### Step 6: Verify Proof

```bash
# Verify the proof
snarkjs groth16 verify \
  build/training/vkey.json \
  build/training/public.json \
  build/training/proof.json

# Expected output:
#   [INFO]  snarkJS: OK!
```

---

## Testing Different Scenarios

### Test 1: Normal Training Step (No Clipping)

```bash
# Generate test with small gradient (won't need clipping)
python zk/circuits/training/generate_test_data.py \
  --clip-threshold 10.0 \
  --output test_no_clip.json

# Compile, prove, verify (same steps as above)
```

### Test 2: Large Gradient (Clipping Applied)

```bash
# Generate test with large gradient (will be clipped)
python zk/circuits/training/generate_test_data.py \
  --clip-threshold 0.1 \
  --output test_with_clip.json

# Compile, prove, verify
```

### Test 3: Different Batch Sizes

```bash
# Small batch
python zk/circuits/training/generate_test_data.py \
  --batch-size 4 \
  --output test_batch4.json

# Note: You'll need to recompile circuit with BATCH_SIZE=4
# Edit sgd_step.circom: component main {...} = TrainingStep(4, 32, 7, 1000);
# Then recompile and test
```

### Test 4: Different Model Dimensions

```bash
# Smaller model
python zk/circuits/training/generate_test_data.py \
  --model-dim 16 \
  --output test_dim16.json

# Note: Recompile circuit with MODEL_DIM=16
# Edit sgd_step.circom: component main {...} = TrainingStep(8, 16, 7, 1000);
```

---

## Troubleshooting

### Issue: "Cannot find module 'circomlib'"

```bash
# Install circomlib in project root
cd /path/to/project
npm install circomlib
```

### Issue: "Constraint count too high"

```bash
# Reduce batch size or model dimension
python generate_test_data.py --batch-size 4 --model-dim 16

# Also update circuit parameters accordingly
```

### Issue: "Witness generation failed"

```bash
# Check test input format
python -m json.tool test_input.json

# Verify all required fields are present:
# - client_id, root_D, root_G, alpha, tau (public)
# - weights_old, features, labels, siblings, pathIndices (private)
```

### Issue: "Verification failed"

```bash
# Check public inputs match
cat build/training/public.json

# Should contain exactly 5 values:
# [client_id, root_D, root_G, alpha, tau]

# Verify gradient commitment is correct
python -c "
import json
with open('test_input.json') as f:
    data = json.load(f)
print('Expected root_G:', data['root_G'])
"
```

---

## Performance Benchmarks

### Expected Performance

| Batch Size | Model Dim | Constraints | Proving Time | Verification Time |
|------------|-----------|-------------|--------------|-------------------|
| 4 | 16 | ~120,000 | ~3 sec | ~2 ms |
| 8 | 32 | ~245,000 | 5-10 sec | ~2 ms |
| 16 | 64 | ~500,000 | 10-20 sec | ~2 ms |
| 32 | 128 | ~1,000,000 | 20-40 sec | ~2 ms |

*Benchmarks on: MacBook Pro M1, 16GB RAM*

### Constraint Breakdown

```
Total: ~245,000 constraints (batch=8, dim=32)

Breakdown:
  - Fixed-point arithmetic: ~120,000 (49%)
  - Merkle tree verification: ~85,000 (35%)
  - Gradient clipping logic: ~25,000 (10%)
  - Vector hashing: ~15,000 (6%)
```

---

## Integration with Component A

### Step 1: Use Component A's Dataset Commitment

```python
# In Component A, we generated root_D
# Use this as input to Component B

# Component A output:
#   root_D = "12345678..."

# Component B input:
#   {
#     "root_D": "12345678...",  # <-- Same value!
#     ...
#   }
```

### Step 2: Verify Both Proofs Together

```bash
# Verify Component A proof (dataset balance)
snarkjs groth16 verify \
  build/balance/vkey.json \
  build/balance/public.json \
  build/balance/proof.json

# Verify Component B proof (training step)
snarkjs groth16 verify \
  build/training/vkey.json \
  build/training/public.json \
  build/training/proof.json

# Both should output: [INFO] snarkJS: OK!
```

### Step 3: Check Commitment Consistency

```python
import json

# Load Component A public inputs
with open('build/balance/public.json') as f:
    public_A = json.load(f)

# Load Component B public inputs
with open('build/training/public.json') as f:
    public_B = json.load(f)

# Extract root_D from both
# Component A: public_A[1] (after client_id)
# Component B: public_B[1] (after client_id)

root_D_from_A = public_A[1]
root_D_from_B = public_B[1]

assert root_D_from_A == root_D_from_B, "Dataset commitment mismatch!"
print("âœ“ Dataset commitments match across components!")
```

---

## Next Steps

### Integration with Component C

Component B outputs `root_G` (gradient commitment), which becomes an input to Component C (Secure Aggregation).

```python
# Component B output:
#   root_G = "67890123..."

# Component C input (future):
#   {
#     "root_G": "67890123...",  # <-- Gradient commitment from B
#     ...
#   }
```

### Complete Pipeline Test

```bash
# 1. Generate dataset and prove balance (Component A)
# 2. Use root_D to prove training step (Component B)  
# 3. Use root_G to prove secure aggregation (Component C)
# 4. Verify all three proofs
```

---

## Summary

âœ… **Component B is ready!**

You can now:
1. âœ… Generate test data for training proofs
2. âœ… Compile the circuit
3. âœ… Generate proofs for valid training steps
4. âœ… Verify proof cryptographically
5. âœ… Integrate with Component A (dataset commitment)
6. ðŸ“ Ready for Component C integration

**Total implementation:** 1,137 lines of Circom + 350 lines of Python

**Status:** Component B Complete âœ…

---

*Last updated: November 11, 2025*
